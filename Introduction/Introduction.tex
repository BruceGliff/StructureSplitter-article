\section{Введение}
\label{sec:Introduction}
Вычисления на видеокартах и видеоускорителях (будем коллективно называть их GPU) являются эффективным средством решения широкого класса практически важных задач. 
Существенный прирост производительности по сравнению с микропроцессором общего назначения (CPU) достигается за счёт наличия у GPU большого числа независимых ядер, способных выполнять вычисления параллельно.
Например, свёрточная нейросеть (CNN) тренируется на GPU в шесть раз быстрее, чем на CPU~\cite{render}. 
Также рендеринг изображений на GPU завершается значительно раньше~\cite{render}.
Тысячи вычислительных потоков GPU совместно достигают производительности в несколько десятков и даже сотен терафлопс. 
Но итоговая производительность программы для GPU (шейдера или кернела) часто также зависит от усилий по оптимизации.
Часть обязанностей здесь ложится на программиста, а часть, особенно связанная с низкоуровневыми вещами -- на компилятор.

Одной из самых долгих операций при вычислениях является работа с памятью. 
Иерархия памяти в видеускорителях отлична от CPU~\cite{MEM}.
Чтение изображений проходит через L1 и L2 кэши, через L3-кэш все операции на чтение/запись данных и запись изображений, которой не хватало в L1 и L2, а так же чтение изображений.
Дополнительно к L3 существует локальная память рабочих групп (shared local memory, SLM).
Все операции производятся в каждом EU (execution unit), из которых состоит subslice, с данными из регистрового файла (general register file, GRF).
Дальше от EU расположен кеш последнего уровня (last level cache, LLC), который уже может делиться между CPU и GPU.
Далее, возможно, встроенная DRAM и затем системная DRAM.
При этом, каждый из перечисленных уровней памяти накладывает свои ощутимые задержки, тем большие, чем дальше происходит доступ к данным.

Структуры - это набор из одной или более переменных, возможно различных типов, сгруппированных под одним именем для удобства обработки~\cite{Kern}.
Они полезны при организации сложных данных особенно в больших программах, так как они позволяют сгруппировать данные таким образом, что с ними можно обращаться как с полями одного объекта.
Поскольку структуры широко распространены в программах, любые действия и оптимизации над ними будут влиять на большое количество приложений, что накладывает дополнительные требования по корректности и стабильности преобразований.

В видеускорителях Intel Xe на низком уровне реализована концепция SIMD - Single Instruction Multiple Data.
Широкая операция производится над всеми значениями в векторе за раз, и каждое значение в векторе вычисляется независимо.
В векторном оптимизаторе Intel Graphics Compiler уже существует стадия, векторизующая различные типы данных~\cite{KEN}.

В этой статье мы представим алгоритм разбиения структур, позволяющий свести сложные структуры к более простым, которые можно будет разложить на регистры видеоускорителя, алгоритм замены инструкций, приведём результаты замеров на тестах из открытого стека рендеринга Intel(OSPray, Embree), предложим дальнейшие возможные улучшения.